{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc4cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2a87b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>5342</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.571</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868</td>\n",
       "      <td>0.451</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577</td>\n",
       "      <td>0.529</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507</td>\n",
       "      <td>0.552</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4391</td>\n",
       "      <td>5939</td>\n",
       "      <td>0.530</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.50</td>\n",
       "      <td>5126</td>\n",
       "      <td>14186</td>\n",
       "      <td>0.525</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580</td>\n",
       "      <td>0.545</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159</td>\n",
       "      <td>0.608</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340</td>\n",
       "      <td>0.586</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508</td>\n",
       "      <td>0.572</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725</td>\n",
       "      <td>0.540</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4716</td>\n",
       "      <td>5915</td>\n",
       "      <td>0.724</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010</td>\n",
       "      <td>0.677</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.511</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.517</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619</td>\n",
       "      <td>0.551</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.544</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3448</td>\n",
       "      <td>5399</td>\n",
       "      <td>0.548</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.579</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975</td>\n",
       "      <td>0.563</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3601</td>\n",
       "      <td>4650</td>\n",
       "      <td>0.493</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3640</td>\n",
       "      <td>6905</td>\n",
       "      <td>0.518</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594</td>\n",
       "      <td>0.513</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3063</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.578</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121</td>\n",
       "      <td>0.547</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3528</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.487</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.629</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4045</td>\n",
       "      <td>17782</td>\n",
       "      <td>0.566</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274</td>\n",
       "      <td>0.663</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4345</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.672</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4449</td>\n",
       "      <td>4639</td>\n",
       "      <td>0.626</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985</td>\n",
       "      <td>0.563</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635</td>\n",
       "      <td>0.603</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611</td>\n",
       "      <td>0.508</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.672</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942</td>\n",
       "      <td>0.571</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.623</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794</td>\n",
       "      <td>0.593</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.00            3571            1976                         0.525   \n",
       "1         9.00            4092            1250                         0.572   \n",
       "2         9.00            3865            1586                         0.580   \n",
       "3         7.50            4870            2351                         0.529   \n",
       "4         8.00            4399             431                         0.544   \n",
       "5        10.00            5342            1333                         0.571   \n",
       "6         8.00            5319           11868                         0.451   \n",
       "7         8.00            5126            2138                         0.553   \n",
       "8         8.00            4447            8577                         0.529   \n",
       "9         7.00            4512            8507                         0.552   \n",
       "10        8.00            4391            5939                         0.530   \n",
       "11        7.50            5126           14186                         0.525   \n",
       "12        7.00            4817            6930                         0.574   \n",
       "13        7.00            4207            6580                         0.545   \n",
       "14        7.00            4332            8159                         0.608   \n",
       "15        7.00            4318           10340                         0.586   \n",
       "16        7.00            4206            8508                         0.572   \n",
       "17        7.00            3718            4725                         0.540   \n",
       "18        7.00            4716            5915                         0.724   \n",
       "19        8.50            4341            6010                         0.677   \n",
       "20        7.00            4593            7834                         0.663   \n",
       "21        8.00            4983             602                         0.602   \n",
       "22        9.00            4897            2449                         0.511   \n",
       "23        9.00            4258            4686                         0.517   \n",
       "24        8.50            4574            2619                         0.551   \n",
       "25        9.00            3721            4746                         0.544   \n",
       "26        8.00            3448            5399                         0.548   \n",
       "27        7.50            3846            9061                         0.579   \n",
       "28        8.00            4188            5975                         0.563   \n",
       "29        9.00            3601            4650                         0.493   \n",
       "30        7.00            3640            6905                         0.518   \n",
       "31        7.00            3333            6594                         0.513   \n",
       "32        8.00            3063            6524                         0.578   \n",
       "33        7.50            3357            4121                         0.547   \n",
       "34        8.00            3528            3495                         0.487   \n",
       "35        6.58            3802            7834                         0.629   \n",
       "36        5.00            4045           17782                         0.566   \n",
       "37        7.00            3897            6385                         0.586   \n",
       "38        8.50            3635            3274                         0.663   \n",
       "39        7.00            4345            3905                         0.672   \n",
       "40        7.00            4449            4639                         0.626   \n",
       "41        7.00            3656            3985                         0.563   \n",
       "42        7.00            4300            3635                         0.603   \n",
       "43        7.00            3745            2611                         0.508   \n",
       "44        6.00            5215            2302                         0.672   \n",
       "45        9.00            4476            3942                         0.571   \n",
       "46        7.00            4296            4083                         0.623   \n",
       "47        7.00            5002            9794                         0.593   \n",
       "\n",
       "    Petrol_Consumption  \n",
       "0                  541  \n",
       "1                  524  \n",
       "2                  561  \n",
       "3                  414  \n",
       "4                  410  \n",
       "5                  457  \n",
       "6                  344  \n",
       "7                  467  \n",
       "8                  464  \n",
       "9                  498  \n",
       "10                 580  \n",
       "11                 471  \n",
       "12                 525  \n",
       "13                 508  \n",
       "14                 566  \n",
       "15                 635  \n",
       "16                 603  \n",
       "17                 714  \n",
       "18                 865  \n",
       "19                 640  \n",
       "20                 649  \n",
       "21                 540  \n",
       "22                 464  \n",
       "23                 547  \n",
       "24                 460  \n",
       "25                 566  \n",
       "26                 577  \n",
       "27                 631  \n",
       "28                 574  \n",
       "29                 534  \n",
       "30                 571  \n",
       "31                 554  \n",
       "32                 577  \n",
       "33                 628  \n",
       "34                 487  \n",
       "35                 644  \n",
       "36                 640  \n",
       "37                 704  \n",
       "38                 648  \n",
       "39                 968  \n",
       "40                 587  \n",
       "41                 699  \n",
       "42                 632  \n",
       "43                 591  \n",
       "44                 782  \n",
       "45                 510  \n",
       "46                 610  \n",
       "47                 524  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"petrol_consumption.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59687e1",
   "metadata": {},
   "source": [
    " # Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3ffc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read given data into DataFrame in python “Iris.csv”. Perform Data \n",
    "#cleaning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869af986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the file is downloaded or accessible locally\n",
    "file_path = \"Iris.csv\"  # Replace with the actual path if needed\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_count = df.isnull().sum()\n",
    "print(missing_values_count)  # If there are missing values, handle them appropriately\n",
    "\n",
    "# Explore the data (optional)\n",
    "print(df.head())  # Display the first few rows\n",
    "print(df.describe())  # Get summary statistics (mean, std, quartiles, etc.)\n",
    "print(df.info())  # View data types and non-null values\n",
    "\n",
    "# Example of data cleaning (if needed)\n",
    "# For example, if there are categorical features with typos or inconsistencies, you might:\n",
    "# df['column_name'] = df['column_name'].str.lower()  # Convert to lowercase\n",
    "# df['column_name'] = df['column_name'].replace({'typo1': 'corrected_value', 'typo2': 'corrected_value'})  # Replace typos\n",
    "\n",
    "# Proceed with your data analysis or modeling tasks using the cleaned DataFrame 'df'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc5754",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After data cleaning, you are required to prepare your dataset for training.  • Separate features and labels. \n",
    "#• Vectorization \n",
    "#• Feature scaling/Normalisation \n",
    "#• Perform Label Encoding  \n",
    "#• Split dataset into training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53291ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming the file is downloaded or accessible locally\n",
    "file_path = \"Iris.csv\"  # Replace with the actual path if needed\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.drop('species', axis=1)  # Replace 'species' with your target column name\n",
    "labels = df['species']\n",
    "\n",
    "# Vectorization (not necessary for numerical features in this case)\n",
    "# If you have categorical features, you might need to use techniques like one-hot encoding\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()  # You can also use MinMaxScaler if needed\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels_encoded, test_size=0.2)  # Adjust test_size as needed\n",
    "\n",
    "print(\"Features (training set) shape:\", X_train.shape)\n",
    "print(\"Labels (training set) shape:\", y_train.shape)\n",
    "print(\"Features (testing set) shape:\", X_test.shape)\n",
    "print(\"Labels (testing set) shape:\", y_test.shape)\n",
    "\n",
    "# Now you have your prepared training and testing data (X_train, X_test, y_train, y_test)\n",
    "# for use in machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36ceaf",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform all types of SVM classifications on the above prepared Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80665ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming the file is downloaded or accessible locally\n",
    "file_path = \"Iris.csv\"  # Replace with the actual path if needed\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.drop('species', axis=1)  # Replace 'species' with your target column name\n",
    "labels = df['species']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels_encoded, test_size=0.2)\n",
    "\n",
    "# Define different SVM classifiers with various kernels\n",
    "svm_linear = SVC(kernel='linear')  # Linear SVM\n",
    "svm_poly = SVC(kernel='poly', degree=3)  # Polynomial SVM, degree=3\n",
    "svm_rbf = SVC(kernel='rbf')  # RBF (Radial Basis Function) SVM\n",
    "\n",
    "# Train each SVM classifier\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_poly = svm_poly.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Evaluate performance (example using accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "\n",
    "print(\"Linear SVM Accuracy:\", accuracy_linear)\n",
    "print(\"Polynomial SVM Accuracy:\", accuracy_poly)\n",
    "print(\"RBF SVM Accuracy:\", accuracy_rbf)\n",
    "\n",
    "# You can further explore hyperparameter tuning for each SVM classifier\n",
    "# using GridSearchCV or RandomizedSearchCV from sklearn.model_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2545",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c74c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion matrix and generate report of f1-score, recall and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87103e52",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['species'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Replace 'species' with your target column name\u001b[39;00m\n\u001b[0;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5352\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['species'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the file is downloaded or accessible locally\n",
    "file_path = \"Iris.csv\"  # Replace with the actual path if needed\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.drop('species', axis=1)  # Replace 'species' with your target column name\n",
    "labels = df['species']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels_encoded, test_size=0.2)\n",
    "\n",
    "# Define different SVM classifiers with various kernels\n",
    "svm_linear = SVC(kernel='linear')  # Linear SVM\n",
    "svm_poly = SVC(kernel='poly', degree=3)  # Polynomial SVM, degree=3\n",
    "svm_rbf = SVC(kernel='rbf')  # RBF (Radial Basis Function) SVM\n",
    "\n",
    "# Train each SVM classifier\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_poly = svm_poly.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Evaluate performance using various metrics\n",
    "print(\"Linear SVM:\")\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "print(\"Polynomial SVM:\")\n",
    "print(classification_report(y_test, y_pred_poly))\n",
    "\n",
    "print(\"RBF SVM:\")\n",
    "print(classification_report(y_test, y_pred_rbf))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title):\n",
    "  \"\"\"Plots a confusion matrix.\"\"\"\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "  # Normalize confusion matrix\n",
    "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title(title)\n",
    "  plt.colorbar(fraction=0.02, pad=0.05)\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "  plt.yticks(tick_marks, class_names)\n",
    "\n",
    "  # Print the data within the confusion matrix cells\n",
    "  thresh = cm_normalized.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.grid(False)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# Get unique class labels for confusion matrix visualization\n",
    "class_names = label_encoder.inverse_transform(np.unique(labels_encoded))\n",
    "\n",
    "# Plot confusion matrices for each SVM classifier\n",
    "plot_confusion_matrix(y_test, y_pred_linear, class_names, \"Linear SVM Confusion Matrix\")\n",
    "plot_confusion_matrix(y_test, y_pred_poly, class_names, \"Polynomial SVM Confusion Matrix\")\n",
    "plot_confusion_matrix(y_test, y_pred_rbf, class_names, \"RBF SVM Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e32940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
